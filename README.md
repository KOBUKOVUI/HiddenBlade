## ğŸ“¦ Pháº§n I: Thu tháº­p dá»¯ liá»‡u

Dá»¯ liá»‡u máº­t kháº©u Ä‘Æ°á»£c tá»•ng há»£p tá»« nhiá»u nguá»“n lá»›n:

- **Rockyou.txt**: 14 triá»‡u máº­t kháº©u

- **LinkedIn leak**: 20 triá»‡u máº­t kháº©u

- **Hotmail**: 1 triá»‡u máº­t kháº©u

- **Thá»±c táº¿** (Viá»‡t hÃ³a, sÆ°u táº§m): 1 triá»‡u máº­t kháº©u

## ğŸ§¹ Pháº§n II: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

- **Lá»c theo Ä‘á»™ dÃ i**: Chá»‰ giá»¯ láº¡i máº­t kháº©u tá»« 4 Ä‘áº¿n 72 kÃ½ tá»± (zxcvbn chá»‰ phÃ¢n tÃ­ch tá»‘i Ä‘a 72 kÃ½ tá»±).

- **Lá»c trÃ¹ng láº·p**: Loáº¡i bá» cÃ¡c máº­t kháº©u bá»‹ láº·p.

- **Loáº¡i bá» máº­t kháº©u khÃ´ng chuáº©n**:
  
  - Chá»©a kÃ½ tá»± láº¡ nhÆ° `\n`, hex, hoáº·c mÃ£ hÃ³a URL.
  
  - CÃ³ cáº¥u trÃºc email: `@gmail`, `@hotmail`,â€¦
  
  - Chá»©a tÃªn miá»n `.com`

- **Lá»c nÃ¢ng cao vá»›i Rockyou**:
  
  - Giá»¯ ~1.5 triá»‡u máº­t kháº©u yáº¿u vÃ  ~600k máº¡nh.
  
  - Táº­p cÃ²n láº¡i chá»‰ giá»¯ máº­t kháº©u máº¡nh vÃ  thá»±c táº¿ hÆ¡n.
  
  - Láº¥y ngáº«u nhiÃªn 25% tá»« Rockyou, táº­p khÃ¡c giá»¯ nguyÃªn Ä‘á»ƒ cÃ¢n báº±ng nhÃ£n.

## ğŸ·ï¸ Pháº§n III: GÃ¡n nhÃ£n vÃ  Ä‘Ã¡nh giÃ¡

- Sá»­ dá»¥ng **zxcvbn** Ä‘á»ƒ gÃ¡n Ä‘iá»ƒm strength (`0â€“4`), tÃ­nh **entropy**.

- Máº­t kháº©u **fair** vÃ  **strong** Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh ká»¹ hÆ¡n qua entropy.

- Sau oversampling, giá»¯ táº­p dá»¯ liá»‡u cÃ¢n báº±ng vá»›i 4 lá»›p: `weak`, `fair`, `medium`, `strong`.
  
  ==================================================
  
  weak: 1,734,734 -> 27.37%
  
  medium: 1,717,970 -> 27.14%
  
  fair: 1,346,700 -> 21.25%
  
  strong 1,535,966 -> 24.24%
  
  ğŸ”¢ ---> TOTAL: 6,337,370

==================================================

## ğŸ§ª Pháº§n IV: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng

CÃ¡c Ä‘áº·c trÆ°ng chÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng trong mÃ´ hÃ¬nh:

| Äáº·c trÆ°ng                                                           | MÃ´ táº£                                             |
| ------------------------------------------------------------------- | ------------------------------------------------- |
| `length`                                                            | Äá»™ dÃ i máº­t kháº©u                                   |
| `entropy_length`                                                    | Äiá»ƒm entropy                                      |
| `count_lower`, `count_upper`, `count_digits`, `count_special_chars` | Sá»‘ lÆ°á»£ng kÃ½ tá»± thÆ°á»ng, in hoa, sá»‘, Ä‘áº·c biá»‡t       |
| `ratio_*`                                                           | Tá»‰ lá»‡ kÃ½ tá»± thÆ°á»ng/in hoa/sá»‘/Ä‘áº·c biá»‡t trÃªn Ä‘á»™ dÃ i |
| `char_diversity`                                                    | Äa dáº¡ng loáº¡i kÃ½ tá»± sá»­ dá»¥ng                        |
| `common_phrase`                                                     | CÃ³ thuá»™c cÃ¡c cá»¥m phá»• biáº¿n khÃ´ng                   |

## ğŸ§  Pháº§n V: Huáº¥n luyá»‡n mÃ´ hÃ¬nh

### 1. Random Forest

MÃ´ hÃ¬nh **Random Forest** Ä‘Æ°á»£c triá»ƒn khai vá»›i cÃ¡c tham sá»‘ sau:

- **Sá»‘ cÃ¢y (trees)**: 300
- **Tá»‰ lá»‡ Ä‘áº·c trÆ°ng Ä‘Æ°á»£c trÃ­ch xuáº¥t**: 60%
- **Äá»™ sÃ¢u tá»‘i Ä‘a (max depth)**: 12
- **KÃ­ch thÆ°á»›c táº­p huáº¥n luyá»‡n**: 5.000.000 máº«u
- **KÃ­ch thÆ°á»›c táº­p kiá»ƒm thá»­ (validation)**: 1.280.000 máº«u

Káº¿t quáº£ Ä‘Ã¡nh giÃ¡:

- **Accuracy**: `0.6961`
- **Precision / Recall / F1-score theo tá»«ng lá»›p**:
  - `Fair`: Precision `0.67`, Recall `0.55`, F1 `0.61`
  - `Medium`: Precision `0.69`, Recall `0.89`, F1 `0.78`
  - `Strong`: Precision `0.62`, Recall `0.75`, F1 `0.68`
  - `Weak`: Precision `0.87`, Recall `0.59`, F1 `0.70`
- **Chá»‰ sá»‘ tá»•ng thá»ƒ**:
  - **TPR**: `0.6961`
  - **FPR**: `0.1013`
  - **TNR**: `0.8987`
  - **FNR**: `0.3039`

ğŸ§¾ **Nháº­n xÃ©t**: MÃ´ hÃ¬nh thá»ƒ hiá»‡n kháº£ nÄƒng phÃ¢n loáº¡i tá»‘t, Ä‘áº·c biá»‡t á»Ÿ cÃ¡c lá»›p â€œmediumâ€ vÃ  â€œstrongâ€. Tuy nhiÃªn, nháº§m láº«n á»Ÿ lá»›p â€œfairâ€ vÃ  â€œweakâ€ váº«n cáº§n Ä‘Æ°á»£c cáº£i thiá»‡n. CÃ³ thá»ƒ Ã¡p dá»¥ng thÃªm ká»¹ thuáº­t nhÆ° boosting hoáº·c tuning thÃªm cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.

### 2.1 Logistic regression: OvR

**Nháº­n xÃ©t tá»•ng quan**  
MÃ´ hÃ¬nh Logistic Regression OvR cho káº¿t quáº£ Ä‘á»™ chÃ­nh xÃ¡c 60.65% trÃªn 1.28 triá»‡u máº«u, vá»›i hiá»‡u nÄƒng tá»‘t á»Ÿ hai thÃ¡i cá»±c â€œweakâ€ vÃ  â€œstrongâ€ nhÆ°ng háº¡n cháº¿ rÃµ rá»‡t á»Ÿ hai lá»›p trung gian â€œfairâ€ vÃ  â€œmediumâ€. Äiá»u nÃ y cho tháº¥y ranh giá»›i giá»¯a cÃ¡c má»©c â€œtrung bÃ¬nhâ€ chÆ°a Ä‘Æ°á»£c Ä‘áº·c trÆ°ng hoÃ¡ Ä‘áº§y Ä‘á»§, cáº§n cáº£i thiá»‡n feature hoáº·c chuyá»ƒn chiáº¿n lÆ°á»£c softmax Ä‘á»ƒ nÃ¢ng cao cháº¥t lÆ°á»£ng phÃ¢n loáº¡i.

---

**Nháº­n xÃ©t ngáº¯n gá»n**  
â€“ MÃ´ hÃ¬nh phÃ¢n biá»‡t tá»‘t hai lá»›p â€œstrongâ€ (recall = 0.85) vÃ  â€œweakâ€ (recall = 0.77), F1â€score Ä‘á»u 0.68.  
â€“ KhÃ³ khÄƒn á»Ÿ hai lá»›p trung gian â€œfairâ€ (recall = 0.40, F1 = 0.50) vÃ  â€œmediumâ€ (recall = 0.41, F1 = 0.51).  
â€“ XÃ¡c suáº¥t â€œfairâ€ dá»… bá»‹ nháº§m thÃ nh â€œstrongâ€ vÃ  â€œmediumâ€ dá»… bá»‹ nháº§m thÃ nh â€œweakâ€.

---

**CÃ¡c thÃ´ng sá»‘ chÃ­nh**

- **Accuracy:** 0.6065

- **Fair:** precision = 0.65 | recall = 0.40 | f1-score = 0.50

- **Medium:** precision = 0.67 | recall = 0.41 | f1-score = 0.51

- **Strong:** precision = 0.56 | recall = 0.85 | f1-score = 0.68

- **Weak:** precision = 0.60 | recall = 0.77 | f1-score = 0.68

- **Macro avg:** precision = 0.62 | recall = 0.61 | f1-score = 0.59

- **Weighted avg:** precision = 0.62 | recall = 0.61 | f1-score = 0.59

### 2.2 Logistic Regression: Softmax

MÃ´ hÃ¬nh Softmax Ä‘Ã£ cáº£i thiá»‡n rÃµ rá»‡t so vá»›i OvR, Ä‘áº¡t **67.23%** accuracy (tÄƒng gáº§n 6.6 Ä‘iá»ƒm pháº§n trÄƒm). Má»i lá»›p Ä‘á»u cÃ³ má»©c precision, recall vÃ  F1â€score Ä‘á»“ng Ä‘á»u hÆ¡n, cho tháº¥y giáº£i phÃ¡p Ä‘a lá»›p (â€œmultinomialâ€) tá»‘i Æ°u hoÃ¡ tá»‘t hÆ¡n ranh giá»›i giá»¯a cÃ¡c má»©c Ä‘á»™.

---

**Chi tiáº¿t theo lá»›p**

- **fair**:
  
  - Precision = 0.66 (tÄƒng nháº¹)
  
  - Recall = 0.55 (tÄƒng tá»« 0.40 â†’ 0.55)
  
  - F1 = 0.60 (tÄƒng tá»« 0.50 â†’ 0.60)  
    â†’ Ranh â€œfairâ€/â€œstrongâ€ Ä‘Ã£ rÃµ hÆ¡n, giáº£m nháº§m láº«n sang â€œstrongâ€.

- **medium**:
  
  - Precision = 0.74 (tÄƒng tá»« 0.67)
  
  - Recall = 0.65 (tÄƒng tá»« 0.41)
  
  - F1 = 0.69 (tÄƒng tá»« 0.51)  
    â†’ Lá»›p trung cáº¥p tiáº¿p tá»¥c dá»… nháº­n diá»‡n hÆ¡n, cáº£ sensitivity vÃ  specificity Ä‘á»u tÄƒng.

- **strong**:
  
  - Precision = 0.61 (tÄƒng tá»« 0.56)
  
  - Recall = 0.74 (giáº£m tá»« 0.85)
  
  - F1 = 0.67 (giáº£m nháº¹ tá»« 0.68)  
    â†’ Ãt â€œfalse alarmsâ€ hÆ¡n (precision cao hÆ¡n), cháº¥p nháº­n giáº£m má»™t chÃºt recall Ä‘á»ƒ cÃ¢n báº±ng vá»›i lá»›p khÃ¡c.

- **weak**:
  
  - Precision = 0.70 (tÄƒng tá»« 0.60)
  
  - Recall = 0.75 (giáº£m nháº¹ tá»« 0.77)
  
  - F1 = 0.72 (tÄƒng tá»« 0.68)  
    â†’ Dá»± Ä‘oÃ¡n â€œweakâ€ chÃ­nh xÃ¡c vÃ  bao phá»§ tá»‘t, F1 cáº£i thiá»‡n.

---

**CÃ¡c chá»‰ sá»‘ tá»•ng thá»ƒ**

- **Accuracy:** 0.6723

- **Macro avg:** precision = 0.68 | recall = 0.67 | F1 = 0.67

- **Weighted avg:** precision = 0.68 | recall = 0.67 | F1 = 0.67

--- 

### 3 SVM 
Model Evaluation Report (Linear SVM)
Dataset & Setup

Tá»•ng sá»‘ máº«u: 1,280,000

CÃ¡c lá»›p (classes): fair, medium, strong, weak

Thuáº­t toÃ¡n: Linear Support Vector Machine (LinearSVC, C=1.0, max_iter=1000)

âœ… Káº¿t quáº£ tá»•ng quan

Accuracy (Äá»™ chÃ­nh xÃ¡c): 60.26%

Macro Average (trung bÃ¬nh trÃªn táº¥t cáº£ lá»›p):

Precision: 0.64

Recall: 0.60

F1-score: 0.57

ğŸ” Classification Report chi tiáº¿t
Class	Precision	Recall	F1-score	Support
fair	0.65	0.35	0.45	320,000
medium	0.76	0.32	0.45	320,000
strong	0.55	0.88	0.67	320,000
weak	0.60	0.86	0.71	320,000

ğŸ‘‰ Äiá»ƒm ná»•i báº­t:

Medium cÃ³ precision khÃ¡ cao (0.76), nhÆ°ng recall tháº¥p (0.32) â†’ model thÆ°á»ng Ä‘oÃ¡n "medium" Ä‘Ãºng, nhÆ°ng bá» sÃ³t nhiá»u trÆ°á»ng há»£p thá»±c sá»± lÃ  "medium".

Strong vÃ  Weak cÃ³ recall ráº¥t cao (0.88 vÃ  0.86), nghÄ©a lÃ  model nháº­n diá»‡n tá»‘t cÃ¡c trÆ°á»ng há»£p thá»±c sá»± lÃ  "strong/weak".

Fair bá»‹ nháº­n diá»‡n kÃ©m (recall chá»‰ 0.35), nghÄ©a lÃ  nhiá»u máº«u fair bá»‹ nháº§m thÃ nh lá»›p khÃ¡c.

ğŸ“‰ Confusion Matrix (TÃ³m táº¯t nháº§m láº«n)
Thá»±c táº¿ â†“ / Dá»± Ä‘oÃ¡n â†’	fair	medium	strong	weak
fair	112,029	61	207,910	0
medium	15,511	103,354	15,370	185,765
strong	39,571	415	280,014	0
weak	5,659	31,913	6,493	275,935

ğŸ‘‰ Äiá»ƒm Ä‘Ã¡ng chÃº Ã½:

Ráº¥t nhiá»u fair bá»‹ nháº§m sang strong (~208k).

Má»™t lÆ°á»£ng lá»›n medium bá»‹ nháº§m sang weak (~186k).

Strong Ä‘a pháº§n Ä‘Æ°á»£c dá»± Ä‘oÃ¡n Ä‘Ãºng (280k/320k).

Weak cÅ©ng Ä‘Æ°á»£c dá»± Ä‘oÃ¡n khÃ¡ chÃ­nh xÃ¡c (276k/320k).

ğŸ“ˆ Chá»‰ sá»‘ chung (Overall Metrics)

True Positive Rate (TPR / Recall): 60.26%

False Positive Rate (FPR): 13.25%

True Negative Rate (TNR / Specificity): 86.75%

False Negative Rate (FNR): 39.74%

ğŸ‘‰ NghÄ©a lÃ :

Model dá»± Ä‘oÃ¡n Ä‘Ãºng khoáº£ng 6/10 trÆ°á»ng há»£p.

CÃ³ kháº£ nÄƒng phÃ¢n biá»‡t tÆ°Æ¡ng Ä‘á»‘i á»•n (TNR ~87%), nhÆ°ng váº«n bá» sÃ³t gáº§n 40% máº«u (FNR cao).

ğŸ“Œ Káº¿t luáº­n & HÆ°á»›ng cáº£i thiá»‡n

SVM cho káº¿t quáº£ tá»‡ hÆ¡n Gradient Boosting (60% vs ~70% accuracy).

Sá»± nháº§m láº«n chá»§ yáº¿u giá»¯a fair â†” strong vÃ  medium â†” weak.

HÆ°á»›ng cáº£i thiá»‡n:

Thá»­ kernel phi tuyáº¿n (RBF, polynomial) thay vÃ¬ Linear SVM.

Äiá»u chá»‰nh C vÃ  tÄƒng max_iter Ä‘á»ƒ há»™i tá»¥ tá»‘t hÆ¡n.

CÃ¢n báº±ng dá»¯ liá»‡u hoáº·c sá»­ dá»¥ng class_weight="balanced" trong SVM.

So sÃ¡nh vá»›i cÃ¡c thuáº­t toÃ¡n boosting (XGBoost, LightGBM) Ä‘á»ƒ xem sá»± khÃ¡c biá»‡t.



### 4 Gradient boost

Model Evaluation Report (Gradient Boosting)
Dataset & Setup

Tá»•ng sá»‘ máº«u: 1,280,000

CÃ¡c lá»›p (classes): fair, medium, strong, weak

Thuáº­t toÃ¡n: Gradient Boosting Classifier

âœ… Káº¿t quáº£ tá»•ng quan

Accuracy (Äá»™ chÃ­nh xÃ¡c): 69.82%

Macro Average (trung bÃ¬nh trÃªn táº¥t cáº£ lá»›p):

Precision: 0.71

Recall: 0.70

F1-score: 0.70

ğŸ” Classification Report chi tiáº¿t
Class	Precision	Recall	F1-score	Support
fair	0.65	0.62	0.63	320,000
medium	0.69	0.89	0.78	320,000
strong	0.64	0.70	0.67	320,000
weak	0.86	0.59	0.70	320,000

Precision cao nháº¥t: lá»›p weak (0.86) â†’ khi model dá»± Ä‘oÃ¡n "weak" thÃ¬ khÃ¡ Ä‘Ã¡ng tin.

Recall cao nháº¥t: lá»›p medium (0.89) â†’ model báº¯t Ä‘Æ°á»£c gáº§n háº¿t cÃ¡c trÆ°á»ng há»£p "medium".

Recall tháº¥p nháº¥t: lá»›p weak (0.59) â†’ nhiá»u trÆ°á»ng há»£p "weak" bá»‹ nháº§m sang lá»›p khÃ¡c.

CÃ¡c lá»›p fair vÃ  strong cÃ³ hiá»‡u nÄƒng trung bÃ¬nh, cáº§n cáº£i thiá»‡n thÃªm.

ğŸ“‰ Confusion Matrix (TÃ³m táº¯t nháº§m láº«n)
Thá»±c táº¿ â†“ / Dá»± Ä‘oÃ¡n â†’	fair	medium	strong	weak
fair	197,249	0	122,748	3
medium	4,157	283,265	2,848	29,730
strong	96,623	0	223,376	1
weak	3,319	124,408	2,475	189,798

ğŸ‘‰ Äiá»ƒm Ä‘Ã¡ng chÃº Ã½:

Ráº¥t nhiá»u máº«u fair bá»‹ nháº§m sang strong (~122k).

Má»™t pháº§n lá»›n weak bá»‹ nháº§m thÃ nh medium (~124k).

ğŸ“ˆ Chá»‰ sá»‘ chung (Overall Metrics)

True Positive Rate (TPR / Recall): 69.82%

False Positive Rate (FPR): 10.06%

True Negative Rate (TNR / Specificity): 89.94%

False Negative Rate (FNR): 30.18%

ğŸ‘‰ NghÄ©a lÃ :

Model dá»± Ä‘oÃ¡n Ä‘Ãºng khoáº£ng 70% cÃ¡c trÆ°á»ng há»£p thá»±c táº¿.

Kháº£ nÄƒng phÃ¢n biá»‡t giá»¯a positive/negative tÆ°Æ¡ng Ä‘á»‘i tá»‘t (TNR ~90%), nhÆ°ng váº«n bá» sÃ³t khoáº£ng 30% máº«u (FNR).

ğŸ“Œ Káº¿t luáº­n & HÆ°á»›ng cáº£i thiá»‡n

Model hoáº¡t Ä‘á»™ng khÃ¡ á»•n Ä‘á»‹nh, accuracy gáº§n 70%, nhÆ°ng váº«n cÃ³ nhiá»u nháº§m láº«n giá»¯a cÃ¡c lá»›p fair â†” strong vÃ  weak â†” medium.

CÃ³ thá»ƒ cáº£i thiá»‡n báº±ng cÃ¡ch:

TÄƒng cÃ¢n báº±ng dá»¯ liá»‡u (class rebalancing / oversampling / focal loss).

Äiá»u chá»‰nh hyperparameter cho Gradient Boosting (learning rate, max depth, n_estimators).

Thá»­ cÃ¡c thuáº­t toÃ¡n boosting khÃ¡c nhÆ° XGBoost / LightGBM / CatBoost Ä‘á»ƒ so sÃ¡nh.

### 5 MLP 
Model Evaluation Report (MLP Classifier)
Dataset & Setup

Tá»•ng sá»‘ máº«u: 1,280,000

CÃ¡c lá»›p (classes): fair, medium, strong, weak

Äáº·c trÆ°ng sá»­ dá»¥ng (features):
entropy, length, count_lower, ratio_lower, count_upper, ratio_upper, count_digits, ratio_digits, count_special_chars, ratio_special_chars, char_diversity, common_phrase

Thuáº­t toÃ¡n: Multi-Layer Perceptron (MLP Neural Network)

Thá»i gian huáº¥n luyá»‡n: ~1684 giÃ¢y (~28 phÃºt)

âœ… Káº¿t quáº£ tá»•ng quan

Accuracy (Äá»™ chÃ­nh xÃ¡c): 69.62%

Macro Average (trung bÃ¬nh trÃªn táº¥t cáº£ lá»›p):

Precision: 0.70

Recall: 0.70

F1-score: 0.70

ğŸ” Classification Report chi tiáº¿t
Class	Precision	Recall	F1-score	Support
fair	0.65	0.63	0.64	320,000
medium	0.72	0.81	0.76	320,000
strong	0.64	0.69	0.66	320,000
weak	0.80	0.66	0.72	320,000

ğŸ‘‰ Nháº­n xÃ©t:

Medium Ä‘áº¡t recall cao nháº¥t (0.81) â†’ model báº¯t Ä‘Æ°á»£c nhiá»u trÆ°á»ng há»£p medium.

Weak cÃ³ precision ráº¥t cao (0.80) â†’ khi dá»± Ä‘oÃ¡n "weak" thÃ¬ Ä‘Ã¡ng tin cáº­y.

Fair vÃ  Strong cÃ¢n báº±ng nhÆ°ng chá»‰ á»Ÿ má»©c trung bÃ¬nh (~0.64â€“0.66 F1).

ğŸ“‰ Confusion Matrix (TÃ³m táº¯t nháº§m láº«n)
Thá»±c táº¿ â†“ / Dá»± Ä‘oÃ¡n â†’	fair	medium	strong	weak
fair	200,779	0	119,182	39
medium	4,186	260,005	2,820	52,989
strong	100,615	0	219,364	21
weak	3,418	103,239	2,354	210,989

ğŸ‘‰ Äiá»ƒm Ä‘Ã¡ng chÃº Ã½:

Ráº¥t nhiá»u fair bá»‹ nháº§m sang strong (~119k).

Weak thÆ°á»ng bá»‹ nháº§m thÃ nh medium (~103k).

Medium Ä‘Æ°á»£c phÃ¢n loáº¡i khÃ¡ tá»‘t (260k Ä‘Ãºng trÃªn 320k).

ğŸ“ˆ Chá»‰ sá»‘ chung (Overall Metrics)

True Positive Rate (TPR / Recall): 69.62%

False Positive Rate (FPR): 10.13%

True Negative Rate (TNR / Specificity): 89.87%

False Negative Rate (FNR): 30.38%

ğŸ‘‰ NghÄ©a lÃ :

Model nháº­n diá»‡n Ä‘Ãºng gáº§n 70% máº«u thá»±c táº¿.

Kháº£ nÄƒng phÃ¢n biá»‡t tá»‘t vá»›i TNR ~90%, nhÆ°ng váº«n bá» sÃ³t khoáº£ng 30% máº«u.

ğŸ“Œ Káº¿t luáº­n & HÆ°á»›ng cáº£i thiá»‡n

MLP cho káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng Gradient Boosting (~70% accuracy) vÃ  tá»‘t hÆ¡n SVM (60%).

Äiá»ƒm máº¡nh: nháº­n diá»‡n tá»‘t medium vÃ  weak.

Äiá»ƒm yáº¿u: nhiá»u nháº§m láº«n giá»¯a fair â†” strong vÃ  weak â†” medium.

CÃ³ thá»ƒ cáº£i thiá»‡n báº±ng:

ThÃªm regularization (dropout, batch norm) Ä‘á»ƒ trÃ¡nh overfitting.

Thá»­ kiáº¿n trÃºc sÃ¢u hÆ¡n hoáº·c thay Ä‘á»•i sá»‘ neurons má»—i layer.

So sÃ¡nh thÃªm vá»›i cÃ¡c thuáº­t toÃ¡n boosting (XGBoost, LightGBM) Ä‘á»ƒ tÃ¬m trade-off tá»‘c Ä‘á»™ vs Ä‘á»™ chÃ­nh xÃ¡c.